{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Officiel Inéxécutable \n",
    "\n",
    "Belle présentation, mamacita\n",
    "\n",
    "Faire une fonction plot qui plot les mêmes résultats que dans le Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Pipeline.train import Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"model_type\": \"GCN\",  # \"GCN\", \"GAT\", \"GIN\", \"GraphSAGE\"\n",
    "               \"n_graph_subsampling\": 0, # the number of running graph subsampling each train graph data run subsampling 5 times: increasing graph data 5 times\n",
    "               \"graph_node_subsampling\": True, # TRUE: removing node randomly to subsampling and augmentation of graph dataset \\n'+\n",
    "                # FALSE: removing edge randomly to subsampling and augmentation of graph dataset\n",
    "               \"graph_subsampling_rate\": 0.2, # graph subsampling rate\n",
    "               \"dataset\": \"DD\", \n",
    "               \"pooling_type\": \"mean\", \n",
    "               \"seed\": 42,\n",
    "               \"n_folds\": 10, \n",
    "               \"cuda\": True, \n",
    "               \"lr\": 0.001, \n",
    "               \"epochs\": 50, \n",
    "               \"weight_decay\":5e-4,\n",
    "               \"batch_size\": 32, \n",
    "               \"dropout\": 0, # dropout rate of layer\n",
    "               \"num_lay\": 5, \n",
    "               \"num_agg_layer\": 2, # the number of graph aggregation layers\n",
    "               \"hidden_agg_lay_size\": 64, # size of hidden graph aggregation layer\n",
    "               \"fc_hidden_size\": 128, # size of fully-connected layer after readout\n",
    "               \"threads\":10, # how many subprocesses to use for data loading\n",
    "               \"random_walk\":True,\n",
    "               \"walk_length\": 20, # walk length of random walk, \n",
    "               \"num_walk\": 10, # num of random walk\n",
    "               \"p\": 0.65, # Possibility to return to the previous vertex, how well you navigate around\n",
    "               \"q\": 0.35, # Possibility of moving away from the previous vertex, how well you are exploring new places\n",
    "               \"print_logger\": 10,  # printing rate\n",
    "               \"eps\":0.0, # for GIN only\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Train(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N trainable parameters: 18498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [1/1178 (0%)]\tLoss: 0.720218 (avg: 0.720218) \tsec/iter: 1.2826\n",
      "Train Epoch: 0 [11/1178 (1%)]\tLoss: 0.653136 (avg: 0.694150) \tsec/iter: 0.0043\n",
      "Train Epoch: 0 [21/1178 (2%)]\tLoss: 0.610380 (avg: 0.682677) \tsec/iter: 0.0021\n",
      "Train Epoch: 0 [31/1178 (3%)]\tLoss: 0.494907 (avg: 0.659356) \tsec/iter: 0.0006\n",
      "Train Epoch: 0 [41/1178 (3%)]\tLoss: 0.280796 (avg: 0.614580) \tsec/iter: 0.0005\n",
      "Train Epoch: 0 [51/1178 (4%)]\tLoss: 1.249260 (avg: 0.638756) \tsec/iter: 0.0012\n",
      "Train Epoch: 0 [61/1178 (5%)]\tLoss: 1.134558 (avg: 0.647622) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [71/1178 (6%)]\tLoss: 0.532958 (avg: 0.669707) \tsec/iter: 0.0012\n",
      "Train Epoch: 0 [81/1178 (7%)]\tLoss: 1.035024 (avg: 0.659656) \tsec/iter: 0.0002\n",
      "Train Epoch: 0 [91/1178 (8%)]\tLoss: 0.476243 (avg: 0.662912) \tsec/iter: 0.0002\n",
      "Train Epoch: 0 [101/1178 (9%)]\tLoss: 0.454992 (avg: 0.659089) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [111/1178 (9%)]\tLoss: 1.007134 (avg: 0.665688) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [121/1178 (10%)]\tLoss: 0.546067 (avg: 0.670544) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [131/1178 (11%)]\tLoss: 0.847748 (avg: 0.673829) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [141/1178 (12%)]\tLoss: 0.559812 (avg: 0.674065) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [151/1178 (13%)]\tLoss: 0.869279 (avg: 0.676483) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [161/1178 (14%)]\tLoss: 0.862325 (avg: 0.677022) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [171/1178 (15%)]\tLoss: 0.831106 (avg: 0.677242) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [181/1178 (15%)]\tLoss: 0.881011 (avg: 0.677655) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [191/1178 (16%)]\tLoss: 0.869546 (avg: 0.677632) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [201/1178 (17%)]\tLoss: 0.603284 (avg: 0.680343) \tsec/iter: 0.0005\n",
      "Train Epoch: 0 [211/1178 (18%)]\tLoss: 0.579950 (avg: 0.679363) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [221/1178 (19%)]\tLoss: 0.832827 (avg: 0.681454) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [231/1178 (20%)]\tLoss: 0.848248 (avg: 0.680504) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [241/1178 (20%)]\tLoss: 0.503279 (avg: 0.675880) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [251/1178 (21%)]\tLoss: 0.422369 (avg: 0.671349) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [261/1178 (22%)]\tLoss: 0.390762 (avg: 0.669542) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [271/1178 (23%)]\tLoss: 1.128111 (avg: 0.670578) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [281/1178 (24%)]\tLoss: 1.005512 (avg: 0.673247) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [291/1178 (25%)]\tLoss: 0.856864 (avg: 0.677372) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [301/1178 (26%)]\tLoss: 0.620842 (avg: 0.678878) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [311/1178 (26%)]\tLoss: 0.850223 (avg: 0.677742) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [321/1178 (27%)]\tLoss: 0.576774 (avg: 0.677774) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [331/1178 (28%)]\tLoss: 0.830276 (avg: 0.678725) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [341/1178 (29%)]\tLoss: 0.758984 (avg: 0.681064) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [351/1178 (30%)]\tLoss: 0.766053 (avg: 0.681570) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [361/1178 (31%)]\tLoss: 0.769490 (avg: 0.681246) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [371/1178 (31%)]\tLoss: 0.739951 (avg: 0.682358) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [381/1178 (32%)]\tLoss: 0.636333 (avg: 0.682392) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [391/1178 (33%)]\tLoss: 0.610641 (avg: 0.681938) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [401/1178 (34%)]\tLoss: 0.767231 (avg: 0.683181) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [411/1178 (35%)]\tLoss: 0.758670 (avg: 0.683522) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [421/1178 (36%)]\tLoss: 0.713417 (avg: 0.684190) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [431/1178 (37%)]\tLoss: 0.753129 (avg: 0.684215) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [441/1178 (37%)]\tLoss: 0.653394 (avg: 0.684473) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [451/1178 (38%)]\tLoss: 0.654650 (avg: 0.684687) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [461/1178 (39%)]\tLoss: 0.644893 (avg: 0.684762) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [471/1178 (40%)]\tLoss: 0.777403 (avg: 0.684802) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [481/1178 (41%)]\tLoss: 0.621752 (avg: 0.684757) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [491/1178 (42%)]\tLoss: 0.741222 (avg: 0.685508) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [501/1178 (43%)]\tLoss: 0.659300 (avg: 0.685743) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [511/1178 (43%)]\tLoss: 0.716694 (avg: 0.686064) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [521/1178 (44%)]\tLoss: 0.686483 (avg: 0.686230) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [531/1178 (45%)]\tLoss: 0.739511 (avg: 0.686177) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [541/1178 (46%)]\tLoss: 0.723364 (avg: 0.686522) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [551/1178 (47%)]\tLoss: 0.729721 (avg: 0.686680) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [561/1178 (48%)]\tLoss: 0.752462 (avg: 0.686430) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [571/1178 (48%)]\tLoss: 0.617431 (avg: 0.686168) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [581/1178 (49%)]\tLoss: 0.763760 (avg: 0.686858) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [591/1178 (50%)]\tLoss: 0.750853 (avg: 0.687027) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [601/1178 (51%)]\tLoss: 0.593252 (avg: 0.686230) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [611/1178 (52%)]\tLoss: 0.577466 (avg: 0.685739) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [621/1178 (53%)]\tLoss: 0.873711 (avg: 0.685655) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [631/1178 (54%)]\tLoss: 0.579651 (avg: 0.686018) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [641/1178 (54%)]\tLoss: 0.551369 (avg: 0.685488) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [651/1178 (55%)]\tLoss: 0.831896 (avg: 0.686228) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [661/1178 (56%)]\tLoss: 0.563964 (avg: 0.685734) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [671/1178 (57%)]\tLoss: 0.565206 (avg: 0.685596) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [681/1178 (58%)]\tLoss: 0.873886 (avg: 0.685514) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [691/1178 (59%)]\tLoss: 0.822170 (avg: 0.686119) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [701/1178 (60%)]\tLoss: 0.569950 (avg: 0.685700) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [711/1178 (60%)]\tLoss: 0.824933 (avg: 0.686015) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [721/1178 (61%)]\tLoss: 0.892359 (avg: 0.685098) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [731/1178 (62%)]\tLoss: 0.537716 (avg: 0.685057) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [741/1178 (63%)]\tLoss: 0.481804 (avg: 0.683805) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [751/1178 (64%)]\tLoss: 0.499534 (avg: 0.684398) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [761/1178 (65%)]\tLoss: 0.540546 (avg: 0.684797) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [771/1178 (65%)]\tLoss: 0.870522 (avg: 0.685123) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [781/1178 (66%)]\tLoss: 0.537296 (avg: 0.684149) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [791/1178 (67%)]\tLoss: 0.848331 (avg: 0.685337) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [801/1178 (68%)]\tLoss: 0.826153 (avg: 0.685565) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [811/1178 (69%)]\tLoss: 0.582165 (avg: 0.685203) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [821/1178 (70%)]\tLoss: 0.887545 (avg: 0.684759) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [831/1178 (71%)]\tLoss: 0.904721 (avg: 0.684184) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [841/1178 (71%)]\tLoss: 0.550600 (avg: 0.684583) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [851/1178 (72%)]\tLoss: 0.532503 (avg: 0.684126) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [861/1178 (73%)]\tLoss: 0.512645 (avg: 0.683581) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [871/1178 (74%)]\tLoss: 1.004562 (avg: 0.683002) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [881/1178 (75%)]\tLoss: 1.040604 (avg: 0.682254) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [891/1178 (76%)]\tLoss: 0.328045 (avg: 0.679882) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [901/1178 (76%)]\tLoss: 0.466028 (avg: 0.681713) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [911/1178 (77%)]\tLoss: 0.399408 (avg: 0.679681) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [921/1178 (78%)]\tLoss: 0.449513 (avg: 0.680671) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [931/1178 (79%)]\tLoss: 1.080131 (avg: 0.680204) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [941/1178 (80%)]\tLoss: 0.502710 (avg: 0.680824) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [951/1178 (81%)]\tLoss: 0.513984 (avg: 0.680821) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [961/1178 (82%)]\tLoss: 0.531482 (avg: 0.681209) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [971/1178 (82%)]\tLoss: 0.487789 (avg: 0.680319) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [981/1178 (83%)]\tLoss: 0.968063 (avg: 0.680266) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [991/1178 (84%)]\tLoss: 0.510420 (avg: 0.680220) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [1001/1178 (85%)]\tLoss: 0.370980 (avg: 0.677850) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1011/1178 (86%)]\tLoss: 1.570781 (avg: 0.676422) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1021/1178 (87%)]\tLoss: 1.094135 (avg: 0.678155) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1031/1178 (88%)]\tLoss: 0.901917 (avg: 0.679427) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1041/1178 (88%)]\tLoss: 0.870192 (avg: 0.679352) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1051/1178 (89%)]\tLoss: 0.930642 (avg: 0.678639) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1061/1178 (90%)]\tLoss: 0.535023 (avg: 0.679249) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1071/1178 (91%)]\tLoss: 0.505006 (avg: 0.678536) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1081/1178 (92%)]\tLoss: 0.906989 (avg: 0.678839) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1091/1178 (93%)]\tLoss: 0.924575 (avg: 0.678501) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1101/1178 (93%)]\tLoss: 0.537380 (avg: 0.679147) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [1111/1178 (94%)]\tLoss: 0.827399 (avg: 0.679967) \tsec/iter: 0.0001\n",
      "Train Epoch: 0 [1121/1178 (95%)]\tLoss: 0.851645 (avg: 0.679491) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1131/1178 (96%)]\tLoss: 0.818194 (avg: 0.679919) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1141/1178 (97%)]\tLoss: 0.821630 (avg: 0.680111) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1151/1178 (98%)]\tLoss: 0.816666 (avg: 0.680269) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1161/1178 (99%)]\tLoss: 0.822518 (avg: 0.680438) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1171/1178 (99%)]\tLoss: 0.768542 (avg: 0.680747) \tsec/iter: 0.0000\n",
      "Train Epoch: 0 [1178/1178 (100%)]\tLoss: 0.613713 (avg: 0.680652) \tsec/iter: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 50): Accuracy: 691/1178 (58.66%)\n",
      "\n",
      "Train Epoch: 1 [1/1178 (0%)]\tLoss: 0.600583 (avg: 0.600583) \tsec/iter: 0.0185\n",
      "Train Epoch: 1 [11/1178 (1%)]\tLoss: 0.628640 (avg: 0.711775) \tsec/iter: 0.0012\n",
      "Train Epoch: 1 [21/1178 (2%)]\tLoss: 0.790902 (avg: 0.698903) \tsec/iter: 0.0009\n",
      "Train Epoch: 1 [31/1178 (3%)]\tLoss: 0.782411 (avg: 0.697881) \tsec/iter: 0.0013\n",
      "Train Epoch: 1 [41/1178 (3%)]\tLoss: 0.621739 (avg: 0.697670) \tsec/iter: 0.0006\n",
      "Train Epoch: 1 [51/1178 (4%)]\tLoss: 0.620394 (avg: 0.694084) \tsec/iter: 0.0003\n",
      "Train Epoch: 1 [61/1178 (5%)]\tLoss: 0.591953 (avg: 0.688642) \tsec/iter: 0.0006\n",
      "Train Epoch: 1 [71/1178 (6%)]\tLoss: 0.865829 (avg: 0.679123) \tsec/iter: 0.0002\n",
      "Train Epoch: 1 [81/1178 (7%)]\tLoss: 0.837412 (avg: 0.686790) \tsec/iter: 0.0002\n",
      "Train Epoch: 1 [91/1178 (8%)]\tLoss: 0.589907 (avg: 0.685789) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [101/1178 (9%)]\tLoss: 0.571805 (avg: 0.686914) \tsec/iter: 0.0004\n",
      "Train Epoch: 1 [111/1178 (9%)]\tLoss: 0.877206 (avg: 0.683637) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [121/1178 (10%)]\tLoss: 0.556588 (avg: 0.682633) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [131/1178 (11%)]\tLoss: 0.561457 (avg: 0.681945) \tsec/iter: 0.0002\n",
      "Train Epoch: 1 [141/1178 (12%)]\tLoss: 0.911081 (avg: 0.679034) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [151/1178 (13%)]\tLoss: 0.524394 (avg: 0.678550) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [161/1178 (14%)]\tLoss: 0.872442 (avg: 0.682607) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [171/1178 (15%)]\tLoss: 0.570730 (avg: 0.683597) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [181/1178 (15%)]\tLoss: 0.550707 (avg: 0.683234) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [191/1178 (16%)]\tLoss: 0.778476 (avg: 0.686619) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [201/1178 (17%)]\tLoss: 0.573079 (avg: 0.685181) \tsec/iter: 0.0002\n",
      "Train Epoch: 1 [211/1178 (18%)]\tLoss: 0.777296 (avg: 0.687602) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [221/1178 (19%)]\tLoss: 0.735065 (avg: 0.688663) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [231/1178 (20%)]\tLoss: 0.751516 (avg: 0.688389) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [241/1178 (20%)]\tLoss: 0.618828 (avg: 0.687559) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [251/1178 (21%)]\tLoss: 0.575163 (avg: 0.686307) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [261/1178 (22%)]\tLoss: 0.596559 (avg: 0.686952) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [271/1178 (23%)]\tLoss: 0.783274 (avg: 0.688192) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [281/1178 (24%)]\tLoss: 0.572772 (avg: 0.686988) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [291/1178 (25%)]\tLoss: 0.851309 (avg: 0.685942) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [301/1178 (26%)]\tLoss: 0.554115 (avg: 0.685763) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [311/1178 (26%)]\tLoss: 0.809542 (avg: 0.687262) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [321/1178 (27%)]\tLoss: 0.820013 (avg: 0.687852) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [331/1178 (28%)]\tLoss: 0.796330 (avg: 0.688241) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [341/1178 (29%)]\tLoss: 0.807709 (avg: 0.688051) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [351/1178 (30%)]\tLoss: 0.845420 (avg: 0.686628) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [361/1178 (31%)]\tLoss: 0.613733 (avg: 0.688931) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [371/1178 (31%)]\tLoss: 0.650063 (avg: 0.689891) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [381/1178 (32%)]\tLoss: 0.626415 (avg: 0.689426) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [391/1178 (33%)]\tLoss: 0.608892 (avg: 0.689147) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [401/1178 (34%)]\tLoss: 0.615484 (avg: 0.688946) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [411/1178 (35%)]\tLoss: 0.583702 (avg: 0.688215) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [421/1178 (36%)]\tLoss: 0.597646 (avg: 0.687949) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [431/1178 (37%)]\tLoss: 0.814474 (avg: 0.687549) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [441/1178 (37%)]\tLoss: 0.574954 (avg: 0.687298) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [451/1178 (38%)]\tLoss: 0.815007 (avg: 0.688207) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [461/1178 (39%)]\tLoss: 0.570814 (avg: 0.687993) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [471/1178 (40%)]\tLoss: 0.580859 (avg: 0.687778) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [481/1178 (41%)]\tLoss: 0.547874 (avg: 0.686320) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [491/1178 (42%)]\tLoss: 0.533442 (avg: 0.685235) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [501/1178 (43%)]\tLoss: 0.529886 (avg: 0.685744) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [511/1178 (43%)]\tLoss: 0.919183 (avg: 0.684678) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [521/1178 (44%)]\tLoss: 0.920065 (avg: 0.684230) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [531/1178 (45%)]\tLoss: 0.927949 (avg: 0.684923) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [541/1178 (46%)]\tLoss: 0.935743 (avg: 0.683919) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [551/1178 (47%)]\tLoss: 0.897583 (avg: 0.684981) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [561/1178 (48%)]\tLoss: 0.880857 (avg: 0.684781) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [571/1178 (48%)]\tLoss: 0.543393 (avg: 0.684092) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [581/1178 (49%)]\tLoss: 0.842427 (avg: 0.684988) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [591/1178 (50%)]\tLoss: 0.537297 (avg: 0.683679) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [601/1178 (51%)]\tLoss: 0.589941 (avg: 0.684731) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [611/1178 (52%)]\tLoss: 0.538410 (avg: 0.684175) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [621/1178 (53%)]\tLoss: 0.551171 (avg: 0.684082) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [631/1178 (54%)]\tLoss: 0.889915 (avg: 0.684500) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [641/1178 (54%)]\tLoss: 0.881093 (avg: 0.684307) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [651/1178 (55%)]\tLoss: 0.852885 (avg: 0.684170) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [661/1178 (56%)]\tLoss: 0.916596 (avg: 0.684051) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [671/1178 (57%)]\tLoss: 0.501905 (avg: 0.683474) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [681/1178 (58%)]\tLoss: 0.890479 (avg: 0.684384) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [691/1178 (59%)]\tLoss: 0.869292 (avg: 0.684274) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [701/1178 (60%)]\tLoss: 0.571799 (avg: 0.684537) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [711/1178 (60%)]\tLoss: 0.587200 (avg: 0.684778) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [721/1178 (61%)]\tLoss: 0.846979 (avg: 0.684317) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [731/1178 (62%)]\tLoss: 0.524909 (avg: 0.683221) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [741/1178 (63%)]\tLoss: 0.515027 (avg: 0.683127) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [751/1178 (64%)]\tLoss: 0.519178 (avg: 0.683060) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [761/1178 (65%)]\tLoss: 0.936482 (avg: 0.682970) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [771/1178 (65%)]\tLoss: 0.967272 (avg: 0.682297) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [781/1178 (66%)]\tLoss: 0.474875 (avg: 0.681602) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [791/1178 (67%)]\tLoss: 0.412431 (avg: 0.680074) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [801/1178 (68%)]\tLoss: 0.460578 (avg: 0.680495) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [811/1178 (69%)]\tLoss: 0.408622 (avg: 0.678810) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [821/1178 (70%)]\tLoss: 0.392185 (avg: 0.678803) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [831/1178 (71%)]\tLoss: 0.361254 (avg: 0.677951) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [841/1178 (71%)]\tLoss: 0.491430 (avg: 0.679658) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [851/1178 (72%)]\tLoss: 0.496145 (avg: 0.678511) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [861/1178 (73%)]\tLoss: 0.942215 (avg: 0.679711) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [871/1178 (74%)]\tLoss: 0.508166 (avg: 0.679799) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [881/1178 (75%)]\tLoss: 0.984987 (avg: 0.678821) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [891/1178 (76%)]\tLoss: 0.501841 (avg: 0.678643) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [901/1178 (76%)]\tLoss: 0.453147 (avg: 0.677988) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [911/1178 (77%)]\tLoss: 0.448629 (avg: 0.677259) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [921/1178 (78%)]\tLoss: 0.379034 (avg: 0.675962) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [931/1178 (79%)]\tLoss: 0.458509 (avg: 0.676878) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [941/1178 (80%)]\tLoss: 0.400866 (avg: 0.675607) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [951/1178 (81%)]\tLoss: 1.169968 (avg: 0.675700) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [961/1178 (82%)]\tLoss: 0.473354 (avg: 0.676440) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [971/1178 (82%)]\tLoss: 1.021957 (avg: 0.675904) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [981/1178 (83%)]\tLoss: 0.481072 (avg: 0.675781) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [991/1178 (84%)]\tLoss: 0.929118 (avg: 0.676829) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1001/1178 (85%)]\tLoss: 0.514213 (avg: 0.676546) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1011/1178 (86%)]\tLoss: 0.917235 (avg: 0.677239) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1021/1178 (87%)]\tLoss: 0.572827 (avg: 0.677730) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1031/1178 (88%)]\tLoss: 0.906498 (avg: 0.677173) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1041/1178 (88%)]\tLoss: 0.455361 (avg: 0.675877) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1051/1178 (89%)]\tLoss: 0.502609 (avg: 0.676297) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1061/1178 (90%)]\tLoss: 0.511018 (avg: 0.676363) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1071/1178 (91%)]\tLoss: 0.886839 (avg: 0.677073) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1081/1178 (92%)]\tLoss: 0.828737 (avg: 0.677580) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1091/1178 (93%)]\tLoss: 0.822916 (avg: 0.677979) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1101/1178 (93%)]\tLoss: 0.601967 (avg: 0.678149) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1111/1178 (94%)]\tLoss: 0.531770 (avg: 0.677522) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1121/1178 (95%)]\tLoss: 0.580559 (avg: 0.678126) \tsec/iter: 0.0002\n",
      "Train Epoch: 1 [1131/1178 (96%)]\tLoss: 0.550853 (avg: 0.677579) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [1141/1178 (97%)]\tLoss: 0.581933 (avg: 0.678153) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1151/1178 (98%)]\tLoss: 0.877718 (avg: 0.677919) \tsec/iter: 0.0000\n",
      "Train Epoch: 1 [1161/1178 (99%)]\tLoss: 0.545038 (avg: 0.677842) \tsec/iter: 0.0002\n",
      "Train Epoch: 1 [1171/1178 (99%)]\tLoss: 0.798981 (avg: 0.678561) \tsec/iter: 0.0001\n",
      "Train Epoch: 1 [1178/1178 (100%)]\tLoss: 0.590307 (avg: 0.678390) \tsec/iter: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 50): Accuracy: 691/1178 (58.66%)\n",
      "\n",
      "Train Epoch: 2 [1/1178 (0%)]\tLoss: 0.569664 (avg: 0.569664) \tsec/iter: 0.0835\n",
      "Train Epoch: 2 [11/1178 (1%)]\tLoss: 0.517443 (avg: 0.595431) \tsec/iter: 0.0099\n",
      "Train Epoch: 2 [21/1178 (2%)]\tLoss: 0.951031 (avg: 0.593877) \tsec/iter: 0.0013\n",
      "Train Epoch: 2 [31/1178 (3%)]\tLoss: 0.497925 (avg: 0.622304) \tsec/iter: 0.0009\n",
      "Train Epoch: 2 [41/1178 (3%)]\tLoss: 0.535920 (avg: 0.649463) \tsec/iter: 0.0011\n",
      "Train Epoch: 2 [51/1178 (4%)]\tLoss: 0.952896 (avg: 0.647791) \tsec/iter: 0.0004\n",
      "Train Epoch: 2 [61/1178 (5%)]\tLoss: 0.965679 (avg: 0.650805) \tsec/iter: 0.0003\n",
      "Train Epoch: 2 [71/1178 (6%)]\tLoss: 0.444584 (avg: 0.639854) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [81/1178 (7%)]\tLoss: 0.453364 (avg: 0.637873) \tsec/iter: 0.0004\n",
      "Train Epoch: 2 [91/1178 (8%)]\tLoss: 0.471820 (avg: 0.643840) \tsec/iter: 0.0004\n",
      "Train Epoch: 2 [101/1178 (9%)]\tLoss: 0.383998 (avg: 0.636812) \tsec/iter: 0.0007\n",
      "Train Epoch: 2 [111/1178 (9%)]\tLoss: 0.446516 (avg: 0.640834) \tsec/iter: 0.0004\n",
      "Train Epoch: 2 [121/1178 (10%)]\tLoss: 0.869331 (avg: 0.659984) \tsec/iter: 0.0005\n",
      "Train Epoch: 2 [131/1178 (11%)]\tLoss: 0.530636 (avg: 0.660266) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [141/1178 (12%)]\tLoss: 0.831275 (avg: 0.667948) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [151/1178 (13%)]\tLoss: 0.800703 (avg: 0.668860) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [161/1178 (14%)]\tLoss: 0.607843 (avg: 0.672084) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [171/1178 (15%)]\tLoss: 0.766000 (avg: 0.674470) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [181/1178 (15%)]\tLoss: 0.630808 (avg: 0.675628) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [191/1178 (16%)]\tLoss: 0.626195 (avg: 0.676008) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [201/1178 (17%)]\tLoss: 0.803463 (avg: 0.676289) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [211/1178 (18%)]\tLoss: 0.835972 (avg: 0.673951) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [221/1178 (19%)]\tLoss: 0.892063 (avg: 0.672713) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [231/1178 (20%)]\tLoss: 0.514889 (avg: 0.672592) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [241/1178 (20%)]\tLoss: 0.890948 (avg: 0.672666) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [251/1178 (21%)]\tLoss: 0.524658 (avg: 0.672672) \tsec/iter: 0.0003\n",
      "Train Epoch: 2 [261/1178 (22%)]\tLoss: 0.511105 (avg: 0.671059) \tsec/iter: 0.0003\n",
      "Train Epoch: 2 [271/1178 (23%)]\tLoss: 0.488943 (avg: 0.669118) \tsec/iter: 0.0003\n",
      "Train Epoch: 2 [281/1178 (24%)]\tLoss: 0.477231 (avg: 0.666809) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [291/1178 (25%)]\tLoss: 0.510941 (avg: 0.671792) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [301/1178 (26%)]\tLoss: 0.873806 (avg: 0.672342) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [311/1178 (26%)]\tLoss: 0.868855 (avg: 0.672350) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [321/1178 (27%)]\tLoss: 0.839100 (avg: 0.673344) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [331/1178 (28%)]\tLoss: 0.474946 (avg: 0.669804) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [341/1178 (29%)]\tLoss: 0.428917 (avg: 0.666280) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [351/1178 (30%)]\tLoss: 0.556193 (avg: 0.672518) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [361/1178 (31%)]\tLoss: 0.563818 (avg: 0.672411) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [371/1178 (31%)]\tLoss: 0.860523 (avg: 0.674084) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [381/1178 (32%)]\tLoss: 0.584041 (avg: 0.673846) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [391/1178 (33%)]\tLoss: 0.913406 (avg: 0.673768) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [401/1178 (34%)]\tLoss: 0.881824 (avg: 0.674480) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [411/1178 (35%)]\tLoss: 0.551213 (avg: 0.673089) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [421/1178 (36%)]\tLoss: 0.527099 (avg: 0.672398) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [431/1178 (37%)]\tLoss: 0.450093 (avg: 0.671699) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [441/1178 (37%)]\tLoss: 0.423210 (avg: 0.667441) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [451/1178 (38%)]\tLoss: 0.955325 (avg: 0.671642) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [461/1178 (39%)]\tLoss: 0.495330 (avg: 0.672446) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [471/1178 (40%)]\tLoss: 0.581909 (avg: 0.673818) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [481/1178 (41%)]\tLoss: 0.883542 (avg: 0.673697) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [491/1178 (42%)]\tLoss: 0.530250 (avg: 0.673155) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [501/1178 (43%)]\tLoss: 0.524749 (avg: 0.673108) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [511/1178 (43%)]\tLoss: 0.934595 (avg: 0.672067) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [521/1178 (44%)]\tLoss: 0.462714 (avg: 0.670972) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [531/1178 (45%)]\tLoss: 0.557585 (avg: 0.673615) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [541/1178 (46%)]\tLoss: 0.546881 (avg: 0.672866) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [551/1178 (47%)]\tLoss: 0.509054 (avg: 0.671948) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [561/1178 (48%)]\tLoss: 0.514855 (avg: 0.672705) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [571/1178 (48%)]\tLoss: 0.554643 (avg: 0.674163) \tsec/iter: 0.0006\n",
      "Train Epoch: 2 [581/1178 (49%)]\tLoss: 0.857191 (avg: 0.674430) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [591/1178 (50%)]\tLoss: 0.788702 (avg: 0.675741) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [601/1178 (51%)]\tLoss: 0.822109 (avg: 0.675688) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [611/1178 (52%)]\tLoss: 0.791879 (avg: 0.676453) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [621/1178 (53%)]\tLoss: 0.618998 (avg: 0.676796) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [631/1178 (54%)]\tLoss: 0.797723 (avg: 0.676781) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [641/1178 (54%)]\tLoss: 0.592400 (avg: 0.676824) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [651/1178 (55%)]\tLoss: 0.585472 (avg: 0.676542) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [661/1178 (56%)]\tLoss: 0.864936 (avg: 0.676598) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [671/1178 (57%)]\tLoss: 0.847644 (avg: 0.676656) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [681/1178 (58%)]\tLoss: 0.550704 (avg: 0.676359) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [691/1178 (59%)]\tLoss: 0.550390 (avg: 0.676406) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [701/1178 (60%)]\tLoss: 0.526658 (avg: 0.675715) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [711/1178 (60%)]\tLoss: 0.937387 (avg: 0.676043) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [721/1178 (61%)]\tLoss: 0.799224 (avg: 0.677020) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [731/1178 (62%)]\tLoss: 0.805239 (avg: 0.677358) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [741/1178 (63%)]\tLoss: 0.793257 (avg: 0.678153) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [751/1178 (64%)]\tLoss: 0.792972 (avg: 0.677858) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [761/1178 (65%)]\tLoss: 0.774673 (avg: 0.678300) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [771/1178 (65%)]\tLoss: 0.810319 (avg: 0.678303) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [781/1178 (66%)]\tLoss: 0.582018 (avg: 0.677981) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [791/1178 (67%)]\tLoss: 0.865793 (avg: 0.678306) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [801/1178 (68%)]\tLoss: 0.563245 (avg: 0.677716) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [811/1178 (69%)]\tLoss: 0.564946 (avg: 0.677987) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [821/1178 (70%)]\tLoss: 0.493372 (avg: 0.676573) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [831/1178 (71%)]\tLoss: 0.453554 (avg: 0.675953) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [841/1178 (71%)]\tLoss: 0.948254 (avg: 0.675881) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [851/1178 (72%)]\tLoss: 0.783468 (avg: 0.677356) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [861/1178 (73%)]\tLoss: 0.582057 (avg: 0.677848) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [871/1178 (74%)]\tLoss: 0.836700 (avg: 0.678017) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [881/1178 (75%)]\tLoss: 0.798571 (avg: 0.678038) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [891/1178 (76%)]\tLoss: 0.812214 (avg: 0.678504) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [901/1178 (76%)]\tLoss: 0.591271 (avg: 0.678384) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [911/1178 (77%)]\tLoss: 0.563800 (avg: 0.678370) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [921/1178 (78%)]\tLoss: 0.864077 (avg: 0.678049) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [931/1178 (79%)]\tLoss: 0.538883 (avg: 0.677689) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [941/1178 (80%)]\tLoss: 0.508105 (avg: 0.677475) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [951/1178 (81%)]\tLoss: 1.019386 (avg: 0.677166) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [961/1178 (82%)]\tLoss: 0.987526 (avg: 0.676699) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [971/1178 (82%)]\tLoss: 0.925935 (avg: 0.676688) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [981/1178 (83%)]\tLoss: 0.849787 (avg: 0.677882) \tsec/iter: 0.0001\n",
      "Train Epoch: 2 [991/1178 (84%)]\tLoss: 0.800891 (avg: 0.678507) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1001/1178 (85%)]\tLoss: 0.589091 (avg: 0.678198) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1011/1178 (86%)]\tLoss: 0.531586 (avg: 0.678014) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1021/1178 (87%)]\tLoss: 0.545830 (avg: 0.678040) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1031/1178 (88%)]\tLoss: 0.604318 (avg: 0.678656) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1041/1178 (88%)]\tLoss: 0.578805 (avg: 0.678614) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [1051/1178 (89%)]\tLoss: 0.771944 (avg: 0.678863) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1061/1178 (90%)]\tLoss: 0.562589 (avg: 0.678443) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1071/1178 (91%)]\tLoss: 0.850889 (avg: 0.678612) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1081/1178 (92%)]\tLoss: 0.845149 (avg: 0.677887) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1091/1178 (93%)]\tLoss: 0.460418 (avg: 0.677346) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1101/1178 (93%)]\tLoss: 0.483517 (avg: 0.677160) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1111/1178 (94%)]\tLoss: 0.519985 (avg: 0.677293) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1121/1178 (95%)]\tLoss: 0.557401 (avg: 0.677590) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1131/1178 (96%)]\tLoss: 0.387542 (avg: 0.676268) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1141/1178 (97%)]\tLoss: 0.420666 (avg: 0.675707) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1151/1178 (98%)]\tLoss: 0.476573 (avg: 0.676594) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1161/1178 (99%)]\tLoss: 0.847629 (avg: 0.677070) \tsec/iter: 0.0002\n",
      "Train Epoch: 2 [1171/1178 (99%)]\tLoss: 0.483621 (avg: 0.676317) \tsec/iter: 0.0000\n",
      "Train Epoch: 2 [1178/1178 (100%)]\tLoss: 0.450369 (avg: 0.676399) \tsec/iter: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 50): Accuracy: 691/1178 (58.66%)\n",
      "\n",
      "Train Epoch: 3 [1/1178 (0%)]\tLoss: 0.939977 (avg: 0.939977) \tsec/iter: 0.0327\n",
      "Train Epoch: 3 [11/1178 (1%)]\tLoss: 0.539945 (avg: 0.667293) \tsec/iter: 0.0016\n",
      "Train Epoch: 3 [21/1178 (2%)]\tLoss: 0.375178 (avg: 0.587693) \tsec/iter: 0.0003\n",
      "Train Epoch: 3 [31/1178 (3%)]\tLoss: 0.374555 (avg: 0.596846) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [41/1178 (3%)]\tLoss: 0.882681 (avg: 0.631244) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [51/1178 (4%)]\tLoss: 0.872819 (avg: 0.648979) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [61/1178 (5%)]\tLoss: 0.500456 (avg: 0.653841) \tsec/iter: 0.0006\n",
      "Train Epoch: 3 [71/1178 (6%)]\tLoss: 0.507929 (avg: 0.644554) \tsec/iter: 0.0007\n",
      "Train Epoch: 3 [81/1178 (7%)]\tLoss: 0.448415 (avg: 0.647869) \tsec/iter: 0.0003\n",
      "Train Epoch: 3 [91/1178 (8%)]\tLoss: 0.997399 (avg: 0.652882) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [101/1178 (9%)]\tLoss: 0.430617 (avg: 0.643907) \tsec/iter: 0.0003\n",
      "Train Epoch: 3 [111/1178 (9%)]\tLoss: 0.415726 (avg: 0.646719) \tsec/iter: 0.0004\n",
      "Train Epoch: 3 [121/1178 (10%)]\tLoss: 0.438903 (avg: 0.652522) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [131/1178 (11%)]\tLoss: 0.468058 (avg: 0.650522) \tsec/iter: 0.0003\n",
      "Train Epoch: 3 [141/1178 (12%)]\tLoss: 0.932809 (avg: 0.656587) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [151/1178 (13%)]\tLoss: 0.524176 (avg: 0.655946) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [161/1178 (14%)]\tLoss: 0.438572 (avg: 0.649889) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [171/1178 (15%)]\tLoss: 0.443140 (avg: 0.647184) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [181/1178 (15%)]\tLoss: 0.518754 (avg: 0.654526) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [191/1178 (16%)]\tLoss: 0.555256 (avg: 0.656862) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [201/1178 (17%)]\tLoss: 0.796214 (avg: 0.657476) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [211/1178 (18%)]\tLoss: 0.829984 (avg: 0.659570) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [221/1178 (19%)]\tLoss: 0.536161 (avg: 0.659634) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [231/1178 (20%)]\tLoss: 0.504401 (avg: 0.661965) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [241/1178 (20%)]\tLoss: 0.806996 (avg: 0.661001) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [251/1178 (21%)]\tLoss: 0.827631 (avg: 0.664042) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [261/1178 (22%)]\tLoss: 0.712262 (avg: 0.665817) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [271/1178 (23%)]\tLoss: 0.718141 (avg: 0.666882) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [281/1178 (24%)]\tLoss: 0.620137 (avg: 0.667552) \tsec/iter: 0.0004\n",
      "Train Epoch: 3 [291/1178 (25%)]\tLoss: 0.811237 (avg: 0.668516) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [301/1178 (26%)]\tLoss: 0.559100 (avg: 0.668313) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [311/1178 (26%)]\tLoss: 0.627355 (avg: 0.668883) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [321/1178 (27%)]\tLoss: 0.645888 (avg: 0.669761) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [331/1178 (28%)]\tLoss: 0.681671 (avg: 0.670130) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [341/1178 (29%)]\tLoss: 0.768669 (avg: 0.670757) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [351/1178 (30%)]\tLoss: 0.803029 (avg: 0.671954) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [361/1178 (31%)]\tLoss: 0.579597 (avg: 0.670254) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [371/1178 (31%)]\tLoss: 0.450203 (avg: 0.670216) \tsec/iter: 0.0003\n",
      "Train Epoch: 3 [381/1178 (32%)]\tLoss: 0.664155 (avg: 0.672788) \tsec/iter: 0.0010\n",
      "Train Epoch: 3 [391/1178 (33%)]\tLoss: 0.685307 (avg: 0.672688) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [401/1178 (34%)]\tLoss: 0.579556 (avg: 0.672337) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [411/1178 (35%)]\tLoss: 0.510126 (avg: 0.671637) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [421/1178 (36%)]\tLoss: 0.947368 (avg: 0.671655) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [431/1178 (37%)]\tLoss: 0.478536 (avg: 0.669881) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [441/1178 (37%)]\tLoss: 0.385387 (avg: 0.667049) \tsec/iter: 0.0002\n",
      "Train Epoch: 3 [451/1178 (38%)]\tLoss: 1.294318 (avg: 0.663517) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [461/1178 (39%)]\tLoss: 0.230960 (avg: 0.657938) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [471/1178 (40%)]\tLoss: 0.224032 (avg: 0.656622) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [481/1178 (41%)]\tLoss: 1.026134 (avg: 0.662357) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [491/1178 (42%)]\tLoss: 0.925082 (avg: 0.664003) \tsec/iter: 0.0003\n",
      "Train Epoch: 3 [501/1178 (43%)]\tLoss: 0.464663 (avg: 0.663174) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [511/1178 (43%)]\tLoss: 0.452125 (avg: 0.661898) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [521/1178 (44%)]\tLoss: 1.071733 (avg: 0.663008) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [531/1178 (45%)]\tLoss: 0.505439 (avg: 0.663660) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [541/1178 (46%)]\tLoss: 1.117885 (avg: 0.662307) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [551/1178 (47%)]\tLoss: 1.002412 (avg: 0.663080) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [561/1178 (48%)]\tLoss: 0.530259 (avg: 0.663990) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [571/1178 (48%)]\tLoss: 0.499126 (avg: 0.664129) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [581/1178 (49%)]\tLoss: 0.820112 (avg: 0.664087) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [591/1178 (50%)]\tLoss: 0.997759 (avg: 0.662402) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [601/1178 (51%)]\tLoss: 0.485152 (avg: 0.662795) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [611/1178 (52%)]\tLoss: 0.513565 (avg: 0.662132) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [621/1178 (53%)]\tLoss: 0.376664 (avg: 0.660398) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [631/1178 (54%)]\tLoss: 0.413211 (avg: 0.661698) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [641/1178 (54%)]\tLoss: 0.434072 (avg: 0.661265) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [651/1178 (55%)]\tLoss: 0.377173 (avg: 0.660245) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [661/1178 (56%)]\tLoss: 0.780066 (avg: 0.661868) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [671/1178 (57%)]\tLoss: 0.873958 (avg: 0.663240) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [681/1178 (58%)]\tLoss: 0.537783 (avg: 0.662751) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [691/1178 (59%)]\tLoss: 0.469317 (avg: 0.661284) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [701/1178 (60%)]\tLoss: 1.063059 (avg: 0.659465) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [711/1178 (60%)]\tLoss: 0.463805 (avg: 0.659683) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [721/1178 (61%)]\tLoss: 0.473186 (avg: 0.661044) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [731/1178 (62%)]\tLoss: 0.628951 (avg: 0.661316) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [741/1178 (63%)]\tLoss: 0.434675 (avg: 0.661098) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [751/1178 (64%)]\tLoss: 0.538457 (avg: 0.659489) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [761/1178 (65%)]\tLoss: 0.425069 (avg: 0.659412) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [771/1178 (65%)]\tLoss: 0.843993 (avg: 0.660555) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [781/1178 (66%)]\tLoss: 0.565304 (avg: 0.660702) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [791/1178 (67%)]\tLoss: 0.565525 (avg: 0.661652) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [801/1178 (68%)]\tLoss: 0.675919 (avg: 0.661942) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [811/1178 (69%)]\tLoss: 0.791711 (avg: 0.662293) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [821/1178 (70%)]\tLoss: 0.827194 (avg: 0.662578) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [831/1178 (71%)]\tLoss: 0.645286 (avg: 0.663175) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [841/1178 (71%)]\tLoss: 0.450272 (avg: 0.662745) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [851/1178 (72%)]\tLoss: 0.730202 (avg: 0.663720) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [861/1178 (73%)]\tLoss: 0.740188 (avg: 0.663874) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [871/1178 (74%)]\tLoss: 0.603129 (avg: 0.664259) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [881/1178 (75%)]\tLoss: 0.748423 (avg: 0.664400) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [891/1178 (76%)]\tLoss: 0.571292 (avg: 0.664100) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [901/1178 (76%)]\tLoss: 1.092472 (avg: 0.664104) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [911/1178 (77%)]\tLoss: 0.464580 (avg: 0.662963) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [921/1178 (78%)]\tLoss: 0.396227 (avg: 0.662360) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [931/1178 (79%)]\tLoss: 0.451673 (avg: 0.664077) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [941/1178 (80%)]\tLoss: 1.053840 (avg: 0.664628) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [951/1178 (81%)]\tLoss: 0.795883 (avg: 0.665146) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [961/1178 (82%)]\tLoss: 0.587326 (avg: 0.665521) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [971/1178 (82%)]\tLoss: 0.914357 (avg: 0.665944) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [981/1178 (83%)]\tLoss: 0.673986 (avg: 0.666079) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [991/1178 (84%)]\tLoss: 0.796888 (avg: 0.666032) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1001/1178 (85%)]\tLoss: 0.710581 (avg: 0.666244) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1011/1178 (86%)]\tLoss: 0.579391 (avg: 0.666110) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1021/1178 (87%)]\tLoss: 0.692368 (avg: 0.666528) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1031/1178 (88%)]\tLoss: 0.446895 (avg: 0.666437) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1041/1178 (88%)]\tLoss: 0.753603 (avg: 0.667625) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1051/1178 (89%)]\tLoss: 0.470390 (avg: 0.667327) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1061/1178 (90%)]\tLoss: 0.863788 (avg: 0.667516) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1071/1178 (91%)]\tLoss: 0.525738 (avg: 0.667441) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1081/1178 (92%)]\tLoss: 0.864480 (avg: 0.667472) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1091/1178 (93%)]\tLoss: 0.888807 (avg: 0.667541) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1101/1178 (93%)]\tLoss: 0.618630 (avg: 0.667356) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1111/1178 (94%)]\tLoss: 0.503245 (avg: 0.667116) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [1121/1178 (95%)]\tLoss: 0.546437 (avg: 0.666868) \tsec/iter: 0.0001\n",
      "Train Epoch: 3 [1131/1178 (96%)]\tLoss: 0.894516 (avg: 0.667002) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1141/1178 (97%)]\tLoss: 0.636187 (avg: 0.667304) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1151/1178 (98%)]\tLoss: 0.625227 (avg: 0.666730) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1161/1178 (99%)]\tLoss: 0.569724 (avg: 0.667192) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1171/1178 (99%)]\tLoss: 0.383065 (avg: 0.666637) \tsec/iter: 0.0000\n",
      "Train Epoch: 3 [1178/1178 (100%)]\tLoss: 0.433752 (avg: 0.666682) \tsec/iter: 0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (epoch 50): Accuracy: 710/1178 (60.27%)\n",
      "\n",
      "Train Epoch: 4 [1/1178 (0%)]\tLoss: 0.965632 (avg: 0.965632) \tsec/iter: 0.0244\n",
      "Train Epoch: 4 [11/1178 (1%)]\tLoss: 0.472419 (avg: 0.664227) \tsec/iter: 0.0021\n",
      "Train Epoch: 4 [21/1178 (2%)]\tLoss: 1.175679 (avg: 0.677679) \tsec/iter: 0.0011\n",
      "Train Epoch: 4 [31/1178 (3%)]\tLoss: 0.409621 (avg: 0.653991) \tsec/iter: 0.0015\n",
      "Train Epoch: 4 [41/1178 (3%)]\tLoss: 0.614524 (avg: 0.663374) \tsec/iter: 0.0007\n",
      "Train Epoch: 4 [51/1178 (4%)]\tLoss: 0.705965 (avg: 0.680737) \tsec/iter: 0.0010\n",
      "Train Epoch: 4 [61/1178 (5%)]\tLoss: 0.588042 (avg: 0.677992) \tsec/iter: 0.0018\n",
      "Train Epoch: 4 [71/1178 (6%)]\tLoss: 0.719390 (avg: 0.670047) \tsec/iter: 0.0001\n",
      "Train Epoch: 4 [81/1178 (7%)]\tLoss: 0.406132 (avg: 0.651340) \tsec/iter: 0.0003\n",
      "Train Epoch: 4 [91/1178 (8%)]\tLoss: 0.413381 (avg: 0.660814) \tsec/iter: 0.0003\n",
      "Train Epoch: 4 [101/1178 (9%)]\tLoss: 0.473571 (avg: 0.649680) \tsec/iter: 0.0006\n",
      "Train Epoch: 4 [111/1178 (9%)]\tLoss: 0.445123 (avg: 0.654421) \tsec/iter: 0.0002\n",
      "Train Epoch: 4 [121/1178 (10%)]\tLoss: 0.898248 (avg: 0.651283) \tsec/iter: 0.0002\n",
      "Train Epoch: 4 [131/1178 (11%)]\tLoss: 0.373841 (avg: 0.640355) \tsec/iter: 0.0004\n",
      "Train Epoch: 4 [141/1178 (12%)]\tLoss: 0.372319 (avg: 0.638212) \tsec/iter: 0.0003\n",
      "Train Epoch: 4 [151/1178 (13%)]\tLoss: 1.209261 (avg: 0.637197) \tsec/iter: 0.0001\n",
      "Train Epoch: 4 [161/1178 (14%)]\tLoss: 0.398087 (avg: 0.639890) \tsec/iter: 0.0001\n",
      "Train Epoch: 4 [171/1178 (15%)]\tLoss: 1.043434 (avg: 0.645262) \tsec/iter: 0.0000\n",
      "Train Epoch: 4 [181/1178 (15%)]\tLoss: 0.703555 (avg: 0.646392) \tsec/iter: 0.0001\n",
      "Train Epoch: 4 [191/1178 (16%)]\tLoss: 0.839528 (avg: 0.651256) \tsec/iter: 0.0002\n",
      "Train Epoch: 4 [201/1178 (17%)]\tLoss: 0.784101 (avg: 0.654874) \tsec/iter: 0.0004\n",
      "Train Epoch: 4 [211/1178 (18%)]\tLoss: 0.656510 (avg: 0.654003) \tsec/iter: 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/MVA/MVA S2/Graphical Models/MVA_Graphical_Models/train.py:300\u001b[0m, in \u001b[0;36mTrain.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stopping_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 300\u001b[0m     total_time_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    301\u001b[0m     total_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_time_iter\n\u001b[1;32m    302\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(loader)  \u001b[38;5;66;03m# Same loader used for train/test (no split)\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/MVA/MVA S2/Graphical Models/MVA_Graphical_Models/train.py:215\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, train_loader, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m    213\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(x)  \u001b[38;5;66;03m# Forward pass for GraphSAGE\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     A, f \u001b[38;5;241m=\u001b[39m \u001b[43mget_adjacency_and_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m     A \u001b[38;5;241m=\u001b[39m A\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    217\u001b[0m     f \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/Documents/MVA/MVA S2/Graphical Models/MVA_Graphical_Models/utils/utils.py:90\u001b[0m, in \u001b[0;36mget_adjacency_and_features\u001b[0;34m(graph_data)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(edge_index[\u001b[38;5;241m0\u001b[39m])):\n\u001b[1;32m     88\u001b[0m     adj_matrix[edge_index[\u001b[38;5;241m0\u001b[39m][i], edge_index[\u001b[38;5;241m1\u001b[39m][i]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m---> 90\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize_adjacency\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj_matrix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m A, features\n",
      "File \u001b[0;32m~/Documents/MVA/MVA S2/Graphical Models/MVA_Graphical_Models/utils/utils.py:55\u001b[0m, in \u001b[0;36mnormalize_adjacency\u001b[0;34m(A)\u001b[0m\n\u001b[1;32m     53\u001b[0m A_hat \u001b[38;5;241m=\u001b[39m A \u001b[38;5;241m+\u001b[39m I  \u001b[38;5;66;03m# Add self-loops\u001b[39;00m\n\u001b[1;32m     54\u001b[0m D_hat \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdiag(torch\u001b[38;5;241m.\u001b[39msum(A_hat, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD_hat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA_hat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mD_hat\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "my_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
