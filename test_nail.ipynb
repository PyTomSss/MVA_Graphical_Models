{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../datasets')\n",
    "from datasets.manager import IMDBBinary, DD\n",
    "import torch \n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from utils.utils import visualise_graph, get_adjacency_and_features\n",
    "from utils.utils import get_adjacency_and_features, create_batch_from_loader\n",
    "#from src.gnn import GNNClassifier\n",
    "\n",
    "from datasets.dataset import *\n",
    "from train import Training\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from src.models import GCN, GAT, GraphDenseNet, GraphSAGE, GIN\n",
    "from datasets.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"model_type\": \"GAT\",  # \"GCN\", \"GAT\", \"GIN\", \"GraphSAGE\"\n",
    "               \"n_graph_subsampling\": 0, # the number of running graph subsampling each train graph data run subsampling 5 times: increasing graph data 5 times\n",
    "               \"graph_node_subsampling\": True, # TRUE: removing node randomly to subsampling and augmentation of graph dataset \\n'+\n",
    "                # FALSE: removing edge randomly to subsampling and augmentation of graph dataset\n",
    "               \"graph_subsampling_rate\": 0.2, # graph subsampling rate\n",
    "               \"dataset\": \"DD\", \n",
    "               \"pooling_type\": \"mean\", \n",
    "               \"seed\": 42,\n",
    "               \"n_folds\": 10, \n",
    "               \"cuda\": True, \n",
    "               \"lr\": 0.001, \n",
    "               \"epochs\": 50, \n",
    "               \"weight_decay\":5e-4,\n",
    "               \"batch_size\": 32, \n",
    "               \"dropout\": 0, # dropout rate of layer\n",
    "               \"num_lay\": 5, \n",
    "               \"num_agg_layer\": 2, # the number of graph aggregation layers\n",
    "               \"hidden_agg_lay_size\": 64, # size of hidden graph aggregation layer\n",
    "               \"fc_hidden_size\": 128, # size of fully-connected layer after readout\n",
    "               \"threads\":10, # how many subprocesses to use for data loading\n",
    "               \"random_walk\":True,\n",
    "               \"walk_length\": 20, # walk length of random walk, \n",
    "               \"num_walk\": 10, # num of random walk\n",
    "               \"p\": 0.65, # Possibility to return to the previous vertex, how well you navigate around\n",
    "               \"q\": 0.35, # Possibility of moving away from the previous vertex, how well you are exploring new places\n",
    "               \"print_logger\": 10,  # printing rate\n",
    "               \"eps\":0.0, # for GIN only\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, params, dataset):\n",
    "      self.params = params \n",
    "      self.x_dataset, self.y_dataset = dataset.dataset.get_data(), dataset.dataset.get_targets()\n",
    "\n",
    "      if self.params[\"cuda\"] and torch.cuda.is_available():\n",
    "          self.device = \"cuda:0\"\n",
    "      else: \n",
    "          self.device = \"cpu\"\n",
    "\n",
    "      self.model = self.get_model()\n",
    "      self.loss_fn = F.cross_entropy \n",
    "\n",
    "    \n",
    "    def get_model(self):\n",
    "        \n",
    "        #adjacency, features = get_adjacency_and_features(self.dataset[0])\n",
    "      \n",
    "        if self.params[\"model_type\"] == 'GCN':\n",
    "          \n",
    "            model = GCN(n_feat = self.x_dataset[0].x.shape[1],  # [N, F] → F\n",
    "                    n_class=2,\n",
    "                    n_layer=self.params['num_agg_layer'],\n",
    "                    agg_hidden=self.params['hidden_agg_lay_size'],\n",
    "                    fc_hidden=self.params['fc_hidden_size'],\n",
    "                    dropout=self.params['dropout'],\n",
    "                    pool_type=self.params['pooling_type'],\n",
    "                    device=self.device).to(self.device)\n",
    "            \n",
    "        elif self.params[\"model_type\"] == 'GAT':\n",
    "            \n",
    "            model = GAT(n_feat=self.x_dataset[0].x.shape[1],\n",
    "                    n_class=2,\n",
    "                    n_layer=self.params['num_agg_layer'],\n",
    "                    agg_hidden=self.params['hidden_agg_lay_size'],\n",
    "                    fc_hidden=self.params['fc_hidden_size'],\n",
    "                    dropout=self.params['dropout'],\n",
    "                    pool_type=self.params['pooling_type'],\n",
    "                    device=self.device).to(self.device)\n",
    "            \n",
    "        elif self.params[\"model_type\"] == 'GraphSAGE':\n",
    "            \n",
    "            model = GraphDenseNet(n_feat=self.x_dataset[0].x.shape[1],\n",
    "                    n_class=2,\n",
    "                    n_layer=self.params['num_agg_layer'],\n",
    "                    agg_hidden=self.params['hidden_agg_lay_size'],\n",
    "                    fc_hidden=self.params['fc_hidden_size'],\n",
    "                    dropout=self.params['dropout'],\n",
    "                    pool_type=self.params[\"pooling_type\"],\n",
    "                    device=self.device).to(self.device)\n",
    "            \n",
    "        elif self.params[\"model_type\"] == 'GIN':\n",
    "            \n",
    "            model = GIN(n_feat=self.x_dataset[0].x.shape[1],\n",
    "                    n_class=2,\n",
    "                    n_layer=self.params['num_agg_layer'],\n",
    "                    agg_hidden=self.params['hidden_agg_lay_size'],\n",
    "                    fc_hidden=self.params['fc_hidden_size'],\n",
    "                    dropout=self.params['dropout'],\n",
    "                    pool_type=self.params[\"pooling_type\"],\n",
    "                    device=self.device).to(self.device)\n",
    "            \n",
    "        return model\n",
    "\n",
    "\n",
    "    def loaders_train_test_setup(self):\n",
    "        # On crée un \"faux\" DataLoader qui donne juste les indices, un par un (pas de batch)\n",
    "        loader = torch.utils.data.DataLoader(\n",
    "            range(len(self.x_dataset)),\n",
    "            batch_size=1,  # important : batch de 1\n",
    "            shuffle=True,\n",
    "            num_workers=0,\n",
    "            pin_memory=True,\n",
    "            drop_last=False,\n",
    "            collate_fn=lambda x: x  # x est une liste d'indices (longueur 1 ici)\n",
    "        )\n",
    "\n",
    "        # Comptage des paramètres\n",
    "        c = sum(p.numel() for p in self.model.parameters() if p.requires_grad)\n",
    "        print('N trainable parameters:', c)\n",
    "\n",
    "        optimizer = optim.Adam(\n",
    "            filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "            lr=self.params[\"lr\"],\n",
    "            weight_decay=self.params[\"weight_decay\"],\n",
    "            betas=(0.5, 0.999)\n",
    "        )\n",
    "\n",
    "        scheduler = lr_scheduler.MultiStepLR(optimizer, [20, 30], gamma=0.1)\n",
    "\n",
    "        return loader, optimizer, scheduler\n",
    "\n",
    "\n",
    "    def train(self, train_loader, optimizer, scheduler, epoch):\n",
    "        self.model.train()\n",
    "        train_loss, n_samples = 0, 0\n",
    "        total_time_iter = 0\n",
    "        start = time.time()\n",
    "\n",
    "        for batch_idx, data_batch in enumerate(train_loader):\n",
    "            # data_batch est une liste d'indices, typiquement [idx]\n",
    "            idx = data_batch[0]\n",
    "\n",
    "            x = self.x_dataset[idx]\n",
    "            y = self.y_dataset[idx]\n",
    "\n",
    "            A, f = get_adjacency_and_features(x)\n",
    "            A = A.to(self.device)\n",
    "            f = f.to(self.device)\n",
    "            y = torch.tensor([y], device=self.device)  # CORRECTION ICI\n",
    "\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = self.model(f, A)  # pas de batching\n",
    "            loss = self.loss_fn(output.unsqueeze(0), y)  # output est [C], y est [1]\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Stat tracking\n",
    "            time_iter = time.time() - start\n",
    "            total_time_iter += time_iter\n",
    "            train_loss += loss.item()\n",
    "            n_samples += 1\n",
    "\n",
    "            if batch_idx % self.params[\"print_logger\"] == 0 or batch_idx == len(train_loader) - 1:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} (avg: {:.6f}) \\tsec/iter: {:.4f}'.format(\n",
    "                    epoch, n_samples, len(train_loader.dataset),\n",
    "                    100. * (batch_idx + 1) / len(train_loader),\n",
    "                    loss.item(), train_loss / n_samples, time_iter / (batch_idx + 1)\n",
    "                ))\n",
    "\n",
    "            start = time.time()  # reset pour la prochaine itération\n",
    "\n",
    "        scheduler.step()\n",
    "        return total_time_iter / (len(train_loader) + 1)\n",
    "\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct, n_samples = 0, 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch_idx, data_batch in enumerate(test_loader):\n",
    "                idx = data_batch[0]  # data_batch est une liste d’indices\n",
    "                x = self.x_dataset[idx]\n",
    "                y = self.y_dataset[idx]\n",
    "\n",
    "                A, f = get_adjacency_and_features(x)\n",
    "                A = A.to(self.device)\n",
    "                f = f.to(self.device)\n",
    "                y = torch.tensor([y], device=self.device)  # CORRECTION ICI\n",
    "\n",
    "\n",
    "                output = self.model(f, A)\n",
    "\n",
    "                # Prédiction (binaire ou multi-class)\n",
    "                if output.shape[-1] == 1:\n",
    "                    pred = (torch.sigmoid(output) > 0.5).long()\n",
    "                else:\n",
    "                    pred = output.argmax(dim=-1)\n",
    "\n",
    "                correct += (pred == y).sum().item()\n",
    "                n_samples += 1\n",
    "\n",
    "        acc = 100. * correct / n_samples\n",
    "        print(f'Test set (epoch {self.params[\"epochs\"]}): Accuracy: {correct}/{n_samples} ({acc:.2f}%)\\n')\n",
    "\n",
    "        return acc\n",
    "\n",
    "    def fit(self): \n",
    "        loader, optimizer, scheduler = self.loaders_train_test_setup()\n",
    "        total_time = 0\n",
    "\n",
    "        best_acc = 0\n",
    "        patience_counter = 0\n",
    "        patience = self.params.get(\"early_stopping_patience\", 5)\n",
    "\n",
    "        for epoch in tqdm(range(self.params[\"epochs\"]), desc=\"Epochs\", position=1, leave=False):\n",
    "            total_time_iter = self.train(loader, optimizer, scheduler, epoch)\n",
    "            total_time += total_time_iter\n",
    "            acc = self.evaluate(loader)  # Même loader pour train/test si pas de split\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "                break\n",
    "\n",
    "        print(f'Best Accuracy: {best_acc:.2f}%')\n",
    "        print(f'Average training time per epoch: {total_time / (epoch + 1):.2f} seconds')\n",
    "\n",
    "        result_list = [self.params[\"dataset\"], self.params[\"dataset\"], best_acc]\n",
    "        return result_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB = IMDBBinary()\n",
    "DD = DD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] GAT: n_feat=89, agg_hidden=64\n",
      "[DEBUG] GraphAttentionLayer: W shape = (89, 64)\n",
      "[DEBUG] GraphAttentionLayer: W shape = (64, 64)\n"
     ]
    }
   ],
   "source": [
    "trainer = Train(params, DD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N trainable parameters: 26946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (436x89 and 64x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[3], line 181\u001b[0m, in \u001b[0;36mTrain.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stopping_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 181\u001b[0m     total_time_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m     total_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_time_iter\n\u001b[1;32m    183\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(loader)  \u001b[38;5;66;03m# Même loader pour train/test si pas de split\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 115\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, train_loader, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m    110\u001b[0m y \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([y], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)  \u001b[38;5;66;03m# CORRECTION ICI\u001b[39;00m\n\u001b[1;32m    113\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m--> 115\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mA\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pas de batching\u001b[39;00m\n\u001b[1;32m    116\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(output\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m), y)  \u001b[38;5;66;03m# output est [C], y est [1]\u001b[39;00m\n\u001b[1;32m    118\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MVA_Graphical_Models/src/models.py:90\u001b[0m, in \u001b[0;36mGAT.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layer):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;66;03m# Application de chaque couche d'attention\u001b[39;00m\n\u001b[1;32m     89\u001b[0m     x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n\u001b[0;32m---> 90\u001b[0m     x_layer \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_attention_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     91\u001b[0m     x_layers\u001b[38;5;241m.\u001b[39mappend(x_layer)\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# Concaténation des sorties de chaque couche d'attention\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MVA_Graphical_Models/src/layer.py:86\u001b[0m, in \u001b[0;36mGraphAttentionLayer.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[38;5;124;03mx: [N, in_features]\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;124;03madj: [N, N]\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m N \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 86\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [N, out_features]\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m# Prepare attention mechanism input (all pairwise combinations)\u001b[39;00m\n\u001b[1;32m     89\u001b[0m a_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([\n\u001b[1;32m     90\u001b[0m     h\u001b[38;5;241m.\u001b[39mrepeat(\u001b[38;5;241m1\u001b[39m, N)\u001b[38;5;241m.\u001b[39mview(N \u001b[38;5;241m*\u001b[39m N, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),        \u001b[38;5;66;03m# h_i\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     h\u001b[38;5;241m.\u001b[39mrepeat(N, \u001b[38;5;241m1\u001b[39m)                          \u001b[38;5;66;03m# h_j\u001b[39;00m\n\u001b[1;32m     92\u001b[0m ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mview(N, N, \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mout_features)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (436x89 and 64x64)"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([327, 327])\n",
      "torch.Size([327, 89])\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "mm(): argument 'input' (position 1) must be Tensor, not GraphData",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# model(f0, A0)\u001b[39;00m\n\u001b[1;32m     11\u001b[0m weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mFloatTensor(\u001b[38;5;241m89\u001b[39m, \u001b[38;5;241m64\u001b[39m))\n\u001b[0;32m---> 12\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: mm(): argument 'input' (position 1) must be Tensor, not GraphData"
     ]
    }
   ],
   "source": [
    "model = trainer.model\n",
    "x_dataset = trainer.x_dataset\n",
    "x0, x1 = x_dataset[0], x_dataset[1]\n",
    "A0, f0 = get_adjacency_and_features(x0)\n",
    "A1, f1 = get_adjacency_and_features(x1)\n",
    "print(A0.shape)\n",
    "print(f0.shape)\n",
    "\n",
    "# model(f0, A0)\n",
    "\n",
    "weight = torch.nn.Parameter(torch.FloatTensor(89, 64))\n",
    "h = torch.mm(x0, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nail_env)",
   "language": "python",
   "name": "nail_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
