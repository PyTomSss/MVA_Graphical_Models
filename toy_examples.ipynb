{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook de test des GNNs sur des Toys Examples : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "sys.path.append('../datasets')\n",
    "from datasets.manager import IMDBBinary, DD\n",
    "import torch \n",
    "import itertools\n",
    "from tqdm import tqdm\n",
    "\n",
    "#from utils.utils import visualise_graph, get_adjacency_and_features\n",
    "from utils.utils import get_adjacency_and_features#, create_batch_from_loader\n",
    "#from src.gnn import GNNClassifier\n",
    "\n",
    "from datasets.dataset import *\n",
    "from train import Train\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "import statistics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from src.models import GCN, GAT\n",
    "from datasets.dataloader import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB = IMDBBinary()\n",
    "DD = DD()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Visualisation du dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_IMBD, y_IMDB = IMDB.dataset.get_data(), IMDB.dataset.get_targets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphData(x=torch.Size([18, 1]), edge_index=torch.Size([2, 153]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node8 = x_IMBD[8]\n",
    "node8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`GraphData(x=torch.Size([18, 1]), edge_index=torch.Size([2, 153]))` refers to a graph that has: \n",
    "- 18 nodes, each having features of dimension 1\n",
    "- 153 edges (each between 2 nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise_graph(8, x_IMBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The adjency matrix of such a graph is computed by `get_adjacency_and_features` and given by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjency matrix:\n",
      "\n",
      "tensor([[0.0556, 0.0572, 0.0589, 0.0609, 0.0630, 0.0654, 0.0680, 0.0711, 0.0745,\n",
      "         0.0786, 0.0833, 0.0891, 0.0962, 0.1054, 0.1179, 0.1361, 0.1667, 0.2357],\n",
      "        [0.0000, 0.0588, 0.0606, 0.0626, 0.0648, 0.0673, 0.0700, 0.0731, 0.0767,\n",
      "         0.0808, 0.0857, 0.0917, 0.0990, 0.1085, 0.1213, 0.1400, 0.1715, 0.2425],\n",
      "        [0.0000, 0.0000, 0.0625, 0.0645, 0.0668, 0.0693, 0.0722, 0.0754, 0.0791,\n",
      "         0.0833, 0.0884, 0.0945, 0.1021, 0.1118, 0.1250, 0.1443, 0.1768, 0.2500],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0667, 0.0690, 0.0716, 0.0745, 0.0778, 0.0816,\n",
      "         0.0861, 0.0913, 0.0976, 0.1054, 0.1155, 0.1291, 0.1491, 0.1826, 0.2582],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0714, 0.0741, 0.0772, 0.0806, 0.0845,\n",
      "         0.0891, 0.0945, 0.1010, 0.1091, 0.1195, 0.1336, 0.1543, 0.1890, 0.2673],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0769, 0.0801, 0.0836, 0.0877,\n",
      "         0.0925, 0.0981, 0.1048, 0.1132, 0.1240, 0.1387, 0.1601, 0.1961, 0.2774],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0833, 0.0870, 0.0913,\n",
      "         0.0962, 0.1021, 0.1091, 0.1179, 0.1291, 0.1443, 0.1667, 0.2041, 0.2887],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0909, 0.0953,\n",
      "         0.1005, 0.1066, 0.1140, 0.1231, 0.1348, 0.1508, 0.1741, 0.2132, 0.3015],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1000,\n",
      "         0.1054, 0.1118, 0.1195, 0.1291, 0.1414, 0.1581, 0.1826, 0.2236, 0.3162],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1111, 0.1179, 0.1260, 0.1361, 0.1491, 0.1667, 0.1925, 0.2357, 0.3333],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.1250, 0.1336, 0.1443, 0.1581, 0.1768, 0.2041, 0.2500, 0.3536],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.1429, 0.1543, 0.1690, 0.1890, 0.2182, 0.2673, 0.3780],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.1667, 0.1826, 0.2041, 0.2357, 0.2887, 0.4082],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.2000, 0.2236, 0.2582, 0.3162, 0.4472],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.2500, 0.2887, 0.3536, 0.5000],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3333, 0.4082, 0.5774],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5000, 0.7071],\n",
      "        [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 1.0000]])\n",
      "Feature vector: \n",
      "\n",
      "tensor([[0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.],\n",
      "        [0.]])\n"
     ]
    }
   ],
   "source": [
    "adjency_mat, feature_vect = get_adjacency_and_features(node8)\n",
    "print(\"Adjency matrix:\\n\")\n",
    "print(adjency_mat)\n",
    "print(\"Feature vector: \\n\")\n",
    "print(feature_vect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implémentation de la cross-validation ; \n",
    "\n",
    "Les hyperparamètres: \n",
    "- Learning Rate\n",
    "- Nombre de Couche de Convolution\n",
    "- Dimension de l'espace d'embedding\n",
    "- Critère d'Early Stopping\n",
    "- dropout / Weight Decay\n",
    "- Batch Size\n",
    "- Nombre d'Epochs\n",
    "\n",
    "Question de mette ou non la feature du degré des noeuds pour voir l'impact sur la performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = {\"model_type\": \"GCN\",  # \"GCN\", \"GAT\", \"GIN\", \"GraphSAGE\"\n",
    "               \"n_graph_subsampling\": 0, # the number of running graph subsampling each train graph data run subsampling 5 times: increasing graph data 5 times\n",
    "               \"graph_node_subsampling\": True, # TRUE: removing node randomly to subsampling and augmentation of graph dataset \\n'+\n",
    "                # FALSE: removing edge randomly to subsampling and augmentation of graph dataset\n",
    "               \"graph_subsampling_rate\": 0.2, # graph subsampling rate\n",
    "               \"dataset\": \"DD\", \n",
    "               \"pooling_type\": \"mean\", \n",
    "               \"seed\": 42,\n",
    "               \"n_folds\": 10, \n",
    "               \"cuda\": True, \n",
    "               \"lr\": [0.0001, 0.001, 0.01], \n",
    "               \"epochs\": 1, \n",
    "               \"weight_decay\":5e-4,\n",
    "               \"batch_size\": 32, \n",
    "               \"dropout\": 0, # dropout rate of layer\n",
    "               \"num_lay\": [1, 2, 3], \n",
    "               \"num_agg_layer\": 2, # the number of graph aggregation layers\n",
    "               \"hidden_agg_lay_size\": [16, 32, 64], # size of hidden graph aggregation layer\n",
    "               \"fc_hidden_size\": 128, # size of fully-connected layer after readout\n",
    "               \"threads\":10, # how many subprocesses to use for data loading\n",
    "               \"random_walk\":True,\n",
    "               \"walk_length\": 20, # walk length of random walk, \n",
    "               \"num_walk\": 10, # num of random walk\n",
    "               \"p\": 0.65, # Possibility to return to the previous vertex, how well you navigate around\n",
    "               \"q\": 0.35, # Possibility of moving away from the previous vertex, how well you are exploring new places\n",
    "               \"print_logger\": 10,  # printing rate\n",
    "               \"eps\":0.0, # for GIN only\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_list = {\"model_type\": \"GCN\",  # \"GCN\", \"GAT\", \"GIN\", \"GraphSAGE\"\n",
    "               \"n_graph_subsampling\": 0, # the number of running graph subsampling each train graph data run subsampling 5 times: increasing graph data 5 times\n",
    "               \"graph_node_subsampling\": True, # TRUE: removing node randomly to subsampling and augmentation of graph dataset \\n'+\n",
    "                # FALSE: removing edge randomly to subsampling and augmentation of graph dataset\n",
    "               \"graph_subsampling_rate\": 0.2, # graph subsampling rate\n",
    "               \"dataset\": \"DD\", \n",
    "               \"pooling_type\": \"mean\", \n",
    "               \"seed\": 42,\n",
    "               \"n_folds\": 10, \n",
    "               \"cuda\": True, \n",
    "               \"lr\": [0.0001, 0.001], \n",
    "               \"epochs\": 1, \n",
    "               \"weight_decay\":5e-4,\n",
    "               \"batch_size\": 32, \n",
    "               \"dropout\": 0, # dropout rate of layer\n",
    "               \"num_lay\": [2, 3], \n",
    "               \"num_agg_layer\": 2, # the number of graph aggregation layers\n",
    "               \"hidden_agg_lay_size\": [16, 32], # size of hidden graph aggregation layer\n",
    "               \"fc_hidden_size\": 128, # size of fully-connected layer after readout\n",
    "               \"threads\":10, # how many subprocesses to use for data loading\n",
    "               \"random_walk\":True,\n",
    "               \"walk_length\": 20, # walk length of random walk, \n",
    "               \"num_walk\": 10, # num of random walk\n",
    "               \"p\": 0.65, # Possibility to return to the previous vertex, how well you navigate around\n",
    "               \"q\": 0.35, # Possibility of moving away from the previous vertex, how well you are exploring new places\n",
    "               \"print_logger\": 10,  # printing rate\n",
    "               \"eps\":0.0, # for GIN only\n",
    "               }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class grid: \n",
    "    \n",
    "    def __init__(self, params_dict): \n",
    "        self.params_dict = params_dict\n",
    "\n",
    "    def get_combinations(self):\n",
    "        keys, values = zip(*self.params_dict.items())\n",
    "        return [dict(zip(keys, v)) for v in itertools.product(*values)]\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"HyperparameterGrid({self.param_dict})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelSelection(): \n",
    "    \n",
    "    def __init__(self, DATASET, data_split, grid, random_search=False, n_samples=10): \n",
    "\n",
    "        self.grid = grid\n",
    "        self.DATASET = DATASET\n",
    "        self.train_split = GraphDatasetSubset(self.DATASET.dataset.get_data(), data_split[\"train\"])\n",
    "        self.validation_split = GraphDatasetSubset(self.DATASET.dataset.get_data(), data_split[\"validation\"])\n",
    "        self.best_config = None\n",
    "        self.random_search = random_search\n",
    "        self.n_samples = n_samples\n",
    "\n",
    "    def fit(self):\n",
    "        dic = {\"lr\" : self.grid[\"lr\"], \"num_lay\" : self.grid[\"num_lay\"], \"hidden_agg_lay_size\" : self.grid[\"hidden_agg_lay_size\"]}\n",
    "        grille = grid(dic)\n",
    "        all_combinations = grille.get_combinations()\n",
    "        \n",
    "        if self.random_search:\n",
    "            combinations_to_try = random.sample(all_combinations, min(self.n_samples, len(all_combinations)))\n",
    "        else:\n",
    "            combinations_to_try = all_combinations\n",
    "\n",
    "        for config in combinations_to_try:\n",
    "            print(f\"Training with configuration: {config}\")\n",
    "            params = self.grid\n",
    "            params[\"lr\"] = config[\"lr\"]\n",
    "            params[\"num_lay\"] = config[\"num_lay\"]\n",
    "            params[\"hidden_agg_lay_size\"] = config[\"hidden_agg_lay_size\"]\n",
    "\n",
    "            print(len(self.train_split))\n",
    "            trainer = Train(params, data = self.train_split)\n",
    "            trainer.fit()\n",
    "            accuracy = trainer.evaluate(self.validation_split, graphDATA = True)\n",
    "\n",
    "            print(f\"Validation accuracy: {accuracy}\")\n",
    "\n",
    "            if self.best_config is None or accuracy > self.best_config[\"accuracy\"]:\n",
    "                self.best_config = {\"config\": params, \"accuracy\": accuracy}\n",
    "        \n",
    "    def get_best_config(self):\n",
    "        if self.best_config is None:\n",
    "            raise ValueError(\"No configurations have been evaluated.\")\n",
    "        return self.best_config[\"config\"], self.best_config[\"accuracy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'lr': 0.0001, 'num_lay': 1, 'hidden_agg_lay_size': 16},\n",
       " {'lr': 0.0001, 'num_lay': 1, 'hidden_agg_lay_size': 32},\n",
       " {'lr': 0.0001, 'num_lay': 1, 'hidden_agg_lay_size': 64},\n",
       " {'lr': 0.0001, 'num_lay': 2, 'hidden_agg_lay_size': 16},\n",
       " {'lr': 0.0001, 'num_lay': 2, 'hidden_agg_lay_size': 32},\n",
       " {'lr': 0.0001, 'num_lay': 2, 'hidden_agg_lay_size': 64},\n",
       " {'lr': 0.001, 'num_lay': 1, 'hidden_agg_lay_size': 16},\n",
       " {'lr': 0.001, 'num_lay': 1, 'hidden_agg_lay_size': 32},\n",
       " {'lr': 0.001, 'num_lay': 1, 'hidden_agg_lay_size': 64},\n",
       " {'lr': 0.001, 'num_lay': 2, 'hidden_agg_lay_size': 16},\n",
       " {'lr': 0.001, 'num_lay': 2, 'hidden_agg_lay_size': 32},\n",
       " {'lr': 0.001, 'num_lay': 2, 'hidden_agg_lay_size': 64}]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic = {\"lr\" : params_list[\"lr\"], \"num_lay\" : [1, 2], \"hidden_agg_lay_size\" : [16, 32, 64]}\n",
    "grille = grid(dic)\n",
    "grille.get_combinations()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Holdout(): \n",
    "    def __init__(self, DATASET, train_split, train_size=0.9): \n",
    "        self.DATASET = DATASET\n",
    "        self.train_split = train_split\n",
    "        self.train_size = train_size\n",
    "        self.num_samples = len(self.train_split)\n",
    "        self.train_indices = None\n",
    "\n",
    "    def split(self):\n",
    "\n",
    "        indices = np.arange(self.num_samples)\n",
    "        np.random.shuffle(indices)\n",
    "        self.train_indices = indices[:int(self.num_samples * self.train_size)]\n",
    "       \n",
    "\n",
    "    def get_splits(self):\n",
    "        if self.train_indices is None :\n",
    "            raise ValueError(\"Data has not been split yet.\")\n",
    "        return self.train_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelAssessment(): \n",
    "    \n",
    "    def __init__(self, DATASET, grid, Kfold=10, holdout=3): \n",
    "        self.DATASET = DATASET\n",
    "        self.grid = grid\n",
    "        self.Kfold = Kfold\n",
    "        self.best_configs = None\n",
    "        self.splits = DATASET.splits\n",
    "        self.holdout = holdout\n",
    "        self.fold_accuracy = []\n",
    "\n",
    "    def assess(self):\n",
    "\n",
    "        for i in tqdm(range(self.Kfold)):\n",
    "            train_data_idxs = self.splits[i][\"model_selection\"][0]\n",
    "            test_data_idxs = self.splits[i][\"test\"]\n",
    "            test_data = GraphDatasetSubset(self.DATASET.dataset.get_data(), test_data_idxs)\n",
    "\n",
    "            model_selection = ModelSelection(self.DATASET, train_data_idxs, self.grid)\n",
    "            model_selection.fit()\n",
    "            best_config, _ = model_selection.get_best_config()\n",
    "            self.best_configs = best_config\n",
    "            inner_accuracy = []\n",
    "\n",
    "            for j in range(self.holdout): \n",
    "                \n",
    "                train_holdout = Holdout(self.DATASET, train_data_idxs)\n",
    "                train_holdout.split()\n",
    "                train_indices = train_holdout.get_splits()\n",
    "                \n",
    "                train_data = GraphDatasetSubset(self.DATASET.dataset.get_data(), train_indices)\n",
    "                model = Train(self.best_configs, train_data)\n",
    "                model.fit()\n",
    "                accuracy = model.evaluate(test_data, graphDATA = True)\n",
    "                inner_accuracy.append(accuracy)\n",
    "            \n",
    "            self.fold_accuracy.append(np.mean(inner_accuracy))\n",
    "        \n",
    "        return np.mean(self.fold_accuracy), np.std(self.fold_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = IMDB.splits[0][\"model_selection\"][0]\n",
    "train_data = GraphDatasetSubset(IMDB.dataset.get_data(), idxs[\"train\"])\n",
    "val_data = GraphDatasetSubset(IMDB.dataset.get_data(), idxs[\"validation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelAssessment__ = ModelAssessment(DD, params_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with configuration: {'lr': 0.0001, 'num_lay': 2, 'hidden_agg_lay_size': 16}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.04 seconds\n",
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n",
      "Training with configuration: {'lr': 0.0001, 'num_lay': 2, 'hidden_agg_lay_size': 32}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.06 seconds\n",
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n",
      "Training with configuration: {'lr': 0.0001, 'num_lay': 3, 'hidden_agg_lay_size': 16}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.04 seconds\n",
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n",
      "Training with configuration: {'lr': 0.0001, 'num_lay': 3, 'hidden_agg_lay_size': 32}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.05 seconds\n",
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n",
      "Training with configuration: {'lr': 0.001, 'num_lay': 2, 'hidden_agg_lay_size': 16}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.04 seconds\n",
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n",
      "Training with configuration: {'lr': 0.001, 'num_lay': 2, 'hidden_agg_lay_size': 32}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.04 seconds\n",
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n",
      "Training with configuration: {'lr': 0.001, 'num_lay': 3, 'hidden_agg_lay_size': 16}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 4146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.04 seconds\n",
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n",
      "Training with configuration: {'lr': 0.001, 'num_lay': 3, 'hidden_agg_lay_size': 32}\n",
      "954\n",
      "taille de x_dataset: 954 et taille de y_dataset : 954\n",
      "N trainable parameters: 8418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 559/954 (58.60%)\n",
      "\n",
      "Best Accuracy: 58.60%\n",
      "Average training time per epoch: 0.04 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [10:40<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62/106 (58.49%)\n",
      "\n",
      "Validation accuracy: 58.490566037735846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'dataset'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mModelAssessment__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[40], line 32\u001b[0m, in \u001b[0;36mModelAssessment.assess\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     29\u001b[0m train_indices \u001b[38;5;241m=\u001b[39m train_holdout\u001b[38;5;241m.\u001b[39mget_splits()\n\u001b[1;32m     31\u001b[0m train_data \u001b[38;5;241m=\u001b[39m GraphDatasetSubset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDATASET\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mget_data(), train_indices)\n\u001b[0;32m---> 32\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mTrain\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_configs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39mfit()\n\u001b[1;32m     34\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(test_data, graphDATA \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/Documents/MVA/MVA S2/Graphical Models/MVA_Graphical_Models/train.py:64\u001b[0m, in \u001b[0;36mTrain.__init__\u001b[0;34m(self, params, data)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, params, data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     28\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Initialize the Trainer class with the provided parameters.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m        - Only supports 'IMDB' or 'DD' datasets as currently coded.\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIMDB\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m IMDBBinary()\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDD\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'dataset'"
     ]
    }
   ],
   "source": [
    "ModelAssessment__.assess()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tente avec une configuration random pour voir si l'entraînement se lance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjency matrix:\n",
      "\n",
      "tensor([[0.2000, 0.1826, 0.2236,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.1667, 0.2041,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.2500,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 1.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 1.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 1.0000]])\n",
      "Feature vector: \n",
      "\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "data = GraphDatasetSubset(DD.dataset.get_data(), idxs[\"train\"])\n",
    "adj, features = get_adjacency_and_features(data[0])\n",
    "print(\"Adjency matrix:\\n\")\n",
    "print(adj)\n",
    "print(\"Feature vector: \\n\")\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "    def __init__(self, params, dataset):\n",
    "      self.params = params \n",
    "      self.x_dataset, self.y_dataset = dataset.dataset.get_data(), dataset.dataset.get_targets()\n",
    "\n",
    "      if self.params[\"cuda\"] and torch.cuda.is_available():\n",
    "          self.device = \"cuda:0\"\n",
    "      else: \n",
    "          self.device = \"cpu\"\n",
    "\n",
    "      self.model = self.get_model()\n",
    "      self.loss_fn = F.cross_entropy \n",
    "\n",
    "    \n",
    "    def get_model(self):\n",
    "        \n",
    "        #adjacency, features = get_adjacency_and_features(self.dataset[0])\n",
    "      \n",
    "        if self.params[\"model_type\"] == 'GCN':\n",
    "          \n",
    "            model = GCN(n_feat = self.x_dataset[0].x.shape[1],  # [N, F] → F\n",
    "                    n_class=2,\n",
    "                    n_layer=self.params['num_agg_layer'],\n",
    "                    agg_hidden=self.params['hidden_agg_lay_size'],\n",
    "                    fc_hidden=self.params['fc_hidden_size'],\n",
    "                    dropout=self.params['dropout'],\n",
    "                    pool_type=self.params['pooling_type'],\n",
    "                    device=self.device).to(self.device)\n",
    "            \n",
    "        elif self.params[\"model_type\"] == 'GAT':\n",
    "            \n",
    "            model = GAT(n_feat=self.x_dataset[0].x.shape[1],\n",
    "                    n_class=2,\n",
    "                    n_layer=self.params['num_agg_layer'],\n",
    "                    agg_hidden=self.params['hidden_agg_lay_size'],\n",
    "                    fc_hidden=self.params['fc_hidden_size'],\n",
    "                    dropout=self.params['dropout'],\n",
    "                    pool_type=self.params['pooling_type'],\n",
    "                    device=self.device).to(self.device)\n",
    "            \n",
    "        elif self.params[\"model_type\"] == 'GraphDenseNet':\n",
    "            \n",
    "            model = GraphDenseNet(n_feat=self.x_dataset[0].x.shape[1],\n",
    "                    n_class=2,\n",
    "                    n_layer=self.params['num_agg_layer'],\n",
    "                    agg_hidden=self.params['hidden_agg_lay_size'],\n",
    "                    fc_hidden=self.params['fc_hidden_size'],\n",
    "                    dropout=self.params['dropout'],\n",
    "                    pool_type=self.params[\"pooling_type\"],\n",
    "                    device=self.device).to(self.device)\n",
    "            \n",
    "        return model\n",
    "\n",
    "\n",
    "    def loaders_train_test_setup(self):\n",
    "\n",
    "        loader = torch.utils.data.DataLoader(range(len(self.x_dataset)),\n",
    "                            batch_size=self.params[\"batch_size\"],\n",
    "                            shuffle=True,\n",
    "                            num_workers=0,\n",
    "                            pin_memory=True,\n",
    "                            drop_last=False,\n",
    "                            collate_fn=lambda x: x)  # x = liste d'indices\n",
    "\n",
    "\n",
    "      \n",
    "      # Total trainable param\n",
    "        c = 0\n",
    "        for p in filter(lambda p: p.requires_grad, self.model.parameters()):\n",
    "            c += p.numel()\n",
    "        print('N trainable parameters:', c)\n",
    "\n",
    "        optimizer = optim.Adam(\n",
    "                        filter(lambda p: p.requires_grad, self.model.parameters()),\n",
    "                        lr=self.params[\"lr\"],\n",
    "                        weight_decay=self.params[\"weight_decay\"],\n",
    "                        betas=(0.5, 0.999))\n",
    "    \n",
    "        scheduler = lr_scheduler.MultiStepLR(optimizer, [20, 30], gamma=0.1)\n",
    "            \n",
    "        return loader, optimizer, scheduler\n",
    "\n",
    "    def train(self, train_loader, optimizer, scheduler, epoch):\n",
    "        total_time_iter = 0\n",
    "        self.model.train()\n",
    "        start = time.time()\n",
    "        train_loss, n_samples = 0, 0\n",
    "\n",
    "        for batch_idx, data_batch in enumerate(train_loader):\n",
    "            # === Préparer le batch manuellement ===\n",
    "            x_batch, adj_batch, y_batch, sizes = create_batch_from_loader(data_batch, self.x_dataset, self.y_dataset, self.device)\n",
    "\n",
    "            # === Forward + backward ===\n",
    "            optimizer.zero_grad()\n",
    "            output = self.model(x_batch, adj_batch)\n",
    "            loss = self.loss_fn(output, y_batch)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # === Stat tracking ===\n",
    "            time_iter = time.time() - start\n",
    "            total_time_iter += time_iter\n",
    "            train_loss += loss.item() * len(y_batch)\n",
    "            n_samples += len(y_batch)\n",
    "\n",
    "            if batch_idx % self.params[\"print_logger\"] == 0 or batch_idx == len(train_loader) - 1:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f} (avg: {:.6f}) \\tsec/iter: {:.4f}'.format(\n",
    "                    epoch, n_samples, len(train_loader.dataset),\n",
    "                    100. * (batch_idx + 1) / len(train_loader), loss.item(), train_loss / n_samples, time_iter / (batch_idx + 1)\n",
    "                ))\n",
    "\n",
    "        scheduler.step()\n",
    "        return total_time_iter / (len(train_loader) + 1)\n",
    "\n",
    "\n",
    "    def evaluate(self, test_loader):\n",
    "        self.model.eval()\n",
    "        correct, n_samples = 0, 0\n",
    "\n",
    "        for batch_idx, data in enumerate(test_loader):\n",
    "            for i in range(len(data)):\n",
    "                data[i] = data[i].to(self.device)\n",
    "            \n",
    "            output = self.model(data)\n",
    "            pred = output.detach().cpu().max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(data[4].detach().cpu().view_as(pred)).sum().item()\n",
    "            n_samples += len(output)\n",
    "\n",
    "        acc = 100. * correct / n_samples\n",
    "        print('Test set (epoch {}): Accuracy: {}/{} ({:.2f}%)\\n'.format(self.params[\"epochs\"], correct, n_samples, acc))\n",
    "        \n",
    "        return acc\n",
    "         \n",
    "              \n",
    "    def fit(self): \n",
    "        loader, optimizer, scheduler = self.loaders_train_test_setup()\n",
    "        total_time = 0\n",
    "\n",
    "        best_acc = 0\n",
    "        patience_counter = 0\n",
    "        patience = self.params.get(\"early_stopping_patience\", 5)\n",
    "\n",
    "        for epoch in tqdm(range(self.params[\"epochs\"]), desc=\"Epochs\", position=1, leave=False):\n",
    "            total_time_iter = self.train(loader, optimizer, scheduler, epoch)\n",
    "            total_time += total_time_iter\n",
    "            acc = self.evaluate(loader)\n",
    "\n",
    "            if acc > best_acc:\n",
    "                best_acc = acc\n",
    "                patience_counter = 0\n",
    "            else:\n",
    "                patience_counter += 1\n",
    "\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "                break\n",
    "\n",
    "        print(f'Best Accuracy: {best_acc:.2f}%')\n",
    "        print(f'Average training time per epoch: {total_time / (epoch + 1):.2f} seconds')\n",
    "\n",
    "        result_list = [self.params[\"dataset\"], self.params[\"dataset\"]]\n",
    "        result_list.append(best_acc)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Train(params_list, IMDB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, features\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m      2\u001b[0m num_agg_layer, hidden_agg_layer_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m----> 3\u001b[0m weights \u001b[38;5;241m=\u001b[39m \u001b[43mnn\u001b[49m\u001b[38;5;241m.\u001b[39mParameter(torch\u001b[38;5;241m.\u001b[39mFloatTensor(num_agg_layer, hidden_agg_layer_size))\n\u001b[1;32m      4\u001b[0m features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(features, weights)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(features\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "features = features.reshape(-1, features.size(1))\n",
    "num_agg_layer, hidden_agg_layer_size = 2, 64\n",
    "weights = nn.Parameter(torch.FloatTensor(num_agg_layer, hidden_agg_layer_size))\n",
    "features = torch.mm(features, weights)\n",
    "print(features.shape)\n",
    "print(adj.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GraphData' object has no attribute 'get_targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m      2\u001b[0m loader \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mdataset\n\u001b[0;32m----> 3\u001b[0m x_batch, adj_batch, y_batch \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_batch_from_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m output \u001b[38;5;241m=\u001b[39m model(x_batch, adj_batch)\n",
      "File \u001b[0;32m~/MVA_Graphical_Models/utils/utils.py:115\u001b[0m, in \u001b[0;36mcreate_batch_from_loader\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m    114\u001b[0m     adj, features \u001b[38;5;241m=\u001b[39m get_adjacency_and_features(data)  \u001b[38;5;66;03m# adj: [N, N], features: [N, F]\u001b[39;00m\n\u001b[0;32m--> 115\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_targets\u001b[49m()[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# int ou tensor scalaire\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    118\u001b[0m         device \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mdevice\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GraphData' object has no attribute 'get_targets'"
     ]
    }
   ],
   "source": [
    "model = trainer.model\n",
    "loader = trainer.dataset\n",
    "x_batch, adj_batch, y_batch = create_batch_from_loader(loader)\n",
    "output = model(x_batch, adj_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N trainable parameters: 12866\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "support shape: torch.Size([650, 64])\n",
      "x shape: torch.Size([650, 1])\n",
      "adj shape: torch.Size([10726, 10726])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (10726x10726 and 650x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[14], line 145\u001b[0m, in \u001b[0;36mTrain.fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    142\u001b[0m patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mearly_stopping_patience\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m\"\u001b[39m]), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpochs\u001b[39m\u001b[38;5;124m\"\u001b[39m, position\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 145\u001b[0m     total_time_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m     total_time \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m total_time_iter\n\u001b[1;32m    147\u001b[0m     acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate(loader)\n",
      "Cell \u001b[0;32mIn[14], line 95\u001b[0m, in \u001b[0;36mTrain.train\u001b[0;34m(self, train_loader, optimizer, scheduler, epoch)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;66;03m# === Forward + backward ===\u001b[39;00m\n\u001b[1;32m     94\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 95\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloss_fn(output, y_batch)\n\u001b[1;32m     98\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MVA_Graphical_Models/src/models.py:29\u001b[0m, in \u001b[0;36mGCN.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, adj):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layer):\n\u001b[0;32m---> 29\u001b[0m         x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph_convolution_layers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43madj\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     31\u001b[0m             x \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mdropout(x, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/MVA_Graphical_Models/src/layer.py:34\u001b[0m, in \u001b[0;36mGraphConvolutionLayer.forward\u001b[0;34m(self, x, adj)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mx\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madj shape: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00madj\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmm\u001b[49m\u001b[43m(\u001b[49m\u001b[43madj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msupport\u001b[49m\u001b[43m)\u001b[49m            \u001b[38;5;66;03m# [N, out_features]\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     output \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (10726x10726 and 650x64)"
     ]
    }
   ],
   "source": [
    "trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (nail_env)",
   "language": "python",
   "name": "nail_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
